{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6oRT12uNHXx/2lqPTvAzc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Que1Pereza2/Mr.CrabsAnalyzer/blob/main/CanYouFeelItNow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports block"
      ],
      "metadata": {
        "id": "g2k6GntyZM4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "bVEQV0c3ZHDb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block reads the None2775.csv file and loads it's contents into review."
      ],
      "metadata": {
        "id": "zpf-RTogZQzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_csv(\"None2775.csv\")"
      ],
      "metadata": {
        "id": "fzLgdgZqUl2w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block handles the undersampling of the positive reviews so the scores appear in equal quantity and creates the label and features arrays used the neural network to train and test."
      ],
      "metadata": {
        "id": "PyCD7YTHaWso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes all the reviews[score] values and replaces the ' \" ' with no space so\n",
        "#they can be converted to int.\n",
        "reviews['score'] = reviews['score'].str.replace('\"', '').astype(int)\n",
        "\n",
        "# Separates all the reviews by score.\n",
        "majority_class = reviews[reviews.score == 1]\n",
        "minority_class = reviews[reviews.score == 0]\n",
        "\n",
        "# Downsample majority class\n",
        "majority_downsampled = majority_class.sample(n = len(minority_class), random_state=42)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "balanced_df = pd.concat([majority_downsampled, minority_class])\n",
        "\n",
        "# Shuffle the resulting DataFrame\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Creates the features and labels arrays\n",
        "features = balanced_df.iloc[:, 0].values\n",
        "labels = balanced_df.iloc[:, 1].values\n"
      ],
      "metadata": {
        "id": "Ie15LZ40ajS9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block converts the scores from strings to ints, uses regex to clean the data and vectorizes the labels DataFrame, which is composed of strings, so the Neural Network can train on it."
      ],
      "metadata": {
        "id": "zehMyw2SHcxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_features = []\n",
        "\n",
        "for sentence in range(0, len(features)):\n",
        "    # Remove all the special characters.\n",
        "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
        "\n",
        "    # Remove all single characters.\n",
        "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "\n",
        "    # Remove single characters from the start.\n",
        "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "\n",
        "    # Substituting multiple spaces with single space.\n",
        "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
        "\n",
        "    # Removing prefixed 'b'.\n",
        "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
        "\n",
        "    # Converting to Lowercase.\n",
        "    processed_feature = processed_feature.lower()\n",
        "\n",
        "    processed_features.append(processed_feature)\n",
        "\n",
        "# Creation of the vectorizer.\n",
        "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8)\n",
        "\n",
        "# Loading the vectorized array back into processed_features.\n",
        "processed_features = vectorizer.fit_transform(processed_features).toarray()"
      ],
      "metadata": {
        "id": "6UECDICLHdZp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block splits the data into train and test arrays and feeds the training data to the Neural Network."
      ],
      "metadata": {
        "id": "9cznXDJOaMVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of the test and train arrays.\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Creation of the Neural Network.\n",
        "text_classifier = RandomForestClassifier(criterion=\"entropy\", n_estimators=2000, random_state=42)\n",
        "\n",
        "# Training the Neural Network.\n",
        "text_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Generating the Test results.\n",
        "predictions = text_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "qqtWoNHMaSQR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network scores."
      ],
      "metadata": {
        "id": "SxrQgf5WZ136"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "J3xfwxO7Z94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Interface."
      ],
      "metadata": {
        "id": "RNOYVDWWLx0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviewToPredict = input(f\"Please provide a review!\\n \")\n",
        "resultUser = text_classifier.predict(vectorizer.transform([reviewToPredict]).toarray())\n",
        "\n",
        "if resultUser == 1:\n",
        "    print(\"The review is positive\")\n",
        "else:\n",
        "    print(\"The review is negative\")"
      ],
      "metadata": {
        "id": "9JhDqxmKVywK",
        "outputId": "80759976-ead7-49e7-8660-fd0fd69aadc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide a review!\n",
            " trash\n",
            "The review is negative\n"
          ]
        }
      ]
    }
  ]
}